# DLD to Cursor AI Prompt Generation System

A sophisticated multi-agent architecture for converting 5G base station Design Low-Level Documents (DLD) into optimized Cursor AI prompts.

## ğŸš€ Overview

This system transforms complex 5G telecommunications DLD documents into high-quality, actionable prompts specifically optimized for Cursor AI code generation. It leverages a multi-agent pipeline with domain expertise, quality assurance, and continuous improvement capabilities.

## ğŸ—ï¸ System Architecture

```mermaid
graph TB
    %% ì…ë ¥ ë° ì¶œë ¥
    A[ğŸ“„ DLD ì…ë ¥<br/>5G í†µì‹  ê¸°ì§€êµ­ ì„¤ê³„ì„œ] --> B[ğŸ¯ Master Agent<br/>ì‘ì—… ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜]
    
    %% Context Validation Agent
    B --> C[ğŸ” Context Validation Agent<br/>DLD ê²€ì¦ ë° ì „ì²˜ë¦¬]
    C --> C1[ğŸ“‹ DLD êµ¬ì¡° ë¶„ì„]
    C --> C2[â— ëˆ„ë½ ì •ë³´ íƒì§€] 
    C --> C3[âœ… ì¼ê´€ì„± ê²€ì¦]
    
    %% Knowledge Base í˜¸ì¶œ (Context Validation)
    C1 -.->|í˜¸ì¶œ| KB1[ğŸ“š 5G ìš©ì–´ ê²€ì¦]
    C2 -.->|í˜¸ì¶œ| KB2[ğŸ“š ê²€ì¦ ê·œì¹™ ì¡°íšŒ]
    C3 -.->|í˜¸ì¶œ| KB3[ğŸ“š ì¼ê´€ì„± ê¸°ì¤€ ì¡°íšŒ]
    
    %% Prompt Generator Agent - 6ë‹¨ê³„ íŒŒì´í”„ë¼ì¸
    C --> D[âš™ï¸ Prompt Generator Agent<br/>í”„ë¡¬í”„íŠ¸ ìƒì„± ì—”ì§„]
    
    D --> D0["0ï¸âƒ£ í”„ë¡œì íŠ¸ ì½”ë“œ êµ¬ì¡° ë¶„ì„<br/>ğŸ“ ë””ë ‰í† ë¦¬ ìŠ¤ìº”<br/>ğŸ”— íŒŒì¼ ì˜ì¡´ì„± ë§µí•‘<br/>ğŸ›ï¸ ì•„í‚¤í…ì²˜ íŒ¨í„´ ì‹ë³„"]
    
    D0 --> D1["1ï¸âƒ£ DLD íŒŒì‹± ë° ë³€í™˜<br/>ğŸ”§ ê¸°ìˆ  ìŠ¤í™ ì¶”ì¶œ<br/>ğŸ“Š ìš”êµ¬ì‚¬í•­ ë¶„ë¥˜<br/>ğŸ“ ë§ˆí¬ë‹¤ìš´ ë³€í™˜<br/>ğŸ’» ì˜ì‚¬ì½”ë“œ ì‹ë³„"]
    
    D1 --> D2["2ï¸âƒ£ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¡œë“œ<br/>ğŸ“¡ 5G ë„ë©”ì¸ ì§€ì‹<br/>ğŸ‘¨â€ğŸ’» ì½”ë”© ê°€ì´ë“œë¼ì¸<br/>â­ í’ˆì§ˆ ê¸°ì¤€"]
    
    D2 --> D3["3ï¸âƒ£ Cursor AI Rules í†µí•©<br/>ğŸ‘¥ íŒ€ ì½”ë”© ì»¨ë²¤ì…˜<br/>ğŸ“ í”„ë¡œì íŠ¸ ê·œì¹™<br/>ğŸ¤– AI í™œìš© ê°€ì´ë“œë¼ì¸"]
    
    D3 --> D4["4ï¸âƒ£ ì½”ë“œ ë§µí•‘ ë¶„ì„<br/>ğŸ”„ DLD-ì½”ë“œ ë§¤ì¹­<br/>ğŸ·ï¸ í•¨ìˆ˜ëª… ë§¤í•‘<br/>ğŸ“¦ ëª¨ë“ˆ êµ¬ì¡° ë¶„ì„"]
    
    D4 --> D5["5ï¸âƒ£ ì½”ë”© ìŠ¤íƒ€ì¼ ì¶”ì¶œ<br/>ğŸ¨ ê¸°ì¡´ ì½”ë“œ íŒ¨í„´ ë¶„ì„<br/>ğŸ“ ë„¤ì´ë° ì»¨ë²¤ì…˜<br/>ğŸ—ï¸ ì•„í‚¤í…ì²˜ ìŠ¤íƒ€ì¼<br/>ğŸ§ª í…ŒìŠ¤íŠ¸ íŒ¨í„´"]
    
    D5 --> D6["6ï¸âƒ£ ì»¨í…ìŠ¤íŠ¸ ë³´ê°•<br/>ğŸ“¡ 5G í”„ë¡œí† ì½œ ì§€ì‹<br/>âš™ï¸ í•˜ë“œì›¨ì–´ ì œì•½ì‚¬í•­<br/>âš¡ ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­"]
    
    %% Knowledge Base í˜¸ì¶œ (Prompt Generator)
    D2 -.->|í˜¸ì¶œ| KB4[ğŸ“š í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿]
    D5 -.->|í˜¸ì¶œ| KB5[ğŸ“š ì½”ë”© íŒ¨í„´]
    D6 -.->|í˜¸ì¶œ| KB6[ğŸ“š 5G ë„ë©”ì¸ ì§€ì‹]
    
    %% Code Quality Agent
    D --> E[ğŸ›¡ï¸ Code Quality Assurance Agent<br/>í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ ê²€ì¦]
    E --> E1[ğŸ“‹ í”„ë¡¬í”„íŠ¸ ì™„ì„±ë„ ê²€ì¦]
    E --> E2[ğŸ”¬ ê¸°ìˆ ì  ì •í™•ì„± í™•ì¸]
    E --> E3[ğŸ¤– Cursor AI í˜¸í™˜ì„± ê²€ì¦]
    
    %% Knowledge Base í˜¸ì¶œ (Quality Agent)
    E1 -.->|í˜¸ì¶œ| KB7[ğŸ“š ì™„ì„±ë„ ê¸°ì¤€]
    E2 -.->|í˜¸ì¶œ| KB8[ğŸ“š ê¸°ìˆ ì  ì •í™•ì„± ê¸°ì¤€]
    E3 -.->|í˜¸ì¶œ| KB9[ğŸ“š Cursor AI í˜¸í™˜ì„± ê¸°ì¤€]
    
    %% LLM Integration
    D6 --> F[ğŸ§  LLM Integration<br/>GPT-5 í”„ë¡¬í”„íŠ¸ ìƒì„±]
    E --> F
    
    %% Prompt Output Agent
    F --> G[ğŸ“¤ Prompt Output Agent<br/>ê²°ê³¼ í›„ì²˜ë¦¬ ë° ìµœì í™”]
    G --> G1[ğŸ“ í”„ë¡¬í”„íŠ¸ êµ¬ì¡°í™”]
    G --> G2[ğŸ”„ Cursor AI í˜•ì‹ ë³€í™˜]
    G --> G3[âœ… ê²€ì¦ ë° í…ŒìŠ¤íŠ¸]
    
    %% ìµœì¢… ì¶œë ¥
    G --> H[ğŸ“‹ ìµœì¢… í”„ë¡¬í”„íŠ¸ ì¶œë ¥]
    
    %% Feedback Loop
    H --> I[ğŸ”„ Feedback Loop<br/>ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§]
    I --> I1[ğŸ“Š ìƒì„± ì½”ë“œ í’ˆì§ˆ ë¶„ì„]
    I --> I2[ğŸ“ˆ í”„ë¡¬í”„íŠ¸ íš¨ê³¼ì„± ì¸¡ì •]
    I --> I3[ğŸ’¡ ê°œì„ ì‚¬í•­ ì‹ë³„]
    
    I -.->|ì €ì¥| KB10[ğŸ“š ì„±ê³µ ì‚¬ë¡€ ì—…ë°ì´íŠ¸]
    I --> B
    
    %% Knowledge Base í†µí•©
    KB1 --> KB[ğŸ“š Knowledge Base<br/>í†µí•© ì§€ì‹ ê´€ë¦¬]
    KB2 --> KB
    KB3 --> KB
    KB4 --> KB
    KB5 --> KB
    KB6 --> KB
    KB7 --> KB
    KB8 --> KB
    KB9 --> KB
    KB10 --> KB
    
    KB --> KB1_comp[ğŸŒ 5G ë„ë©”ì¸ ì˜¨í†¨ë¡œì§€]
    KB --> KB2_comp[ğŸ”§ ì½”ë”© íŒ¨í„´ ë¼ì´ë¸ŒëŸ¬ë¦¬]
    KB --> KB3_comp[ğŸ“ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿]
    KB --> KB4_comp[ğŸ† ì„±ê³µ ì‚¬ë¡€ ë°ì´í„°ë² ì´ìŠ¤]
    
    %% ìŠ¤íƒ€ì¼ë§
    classDef inputOutput fill:#e1f5fe,stroke:#01579b,stroke-width:2px
    classDef masterAgent fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef promptGen fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef qualityAssurance fill:#ffebee,stroke:#b71c1c,stroke-width:2px
    classDef feedback fill:#f1f8e9,stroke:#33691e,stroke-width:2px
    classDef knowledge fill:#fce4ec,stroke:#880e4f,stroke-width:2px
    classDef knowledgeCall stroke:#e91e63,stroke-width:3px,stroke-dasharray: 5 5
    
    class A,H inputOutput
    class B masterAgent
    class D,D0,D1,D2,D3,D4,D5,D6 promptGen
    class E,E1,E2,E3 qualityAssurance
    class I,I1,I2,I3 feedback
    class KB,KB1,KB2,KB3,KB4,KB5,KB6,KB7,KB8,KB9,KB10,KB1_comp,KB2_comp,KB3_comp,KB4_comp knowledge
```

## ğŸ“Š Data Flow Architecture

```mermaid
sequenceDiagram
    participant User as ğŸ‘¤ ì‚¬ìš©ì
    participant API as ğŸŒ REST API
    participant Master as ğŸ¯ Master Agent
    participant Context as ğŸ” Context Validation
    participant Prompt as âš™ï¸ Prompt Generator
    participant Quality as ğŸ›¡ï¸ Quality Agent
    participant LLM as ğŸ§  LLM Integration
    participant Output as ğŸ“¤ Output Agent
    participant Feedback as ğŸ”„ Feedback Loop
    participant KB as ğŸ“š Knowledge Base
    
    User->>API: DLD ë¬¸ì„œ ì—…ë¡œë“œ
    API->>Master: ì²˜ë¦¬ ìš”ì²­
    
    Note over Master: 1ë‹¨ê³„: Context Validation
    Master->>Context: DLD ê²€ì¦ ì‹œì‘
    Context->>KB: 5G ìš©ì–´ ê²€ì¦ ìš”ì²­
    KB-->>Context: ë„ë©”ì¸ ì˜¨í†¨ë¡œì§€ ë°˜í™˜
    Context->>KB: ê²€ì¦ ê·œì¹™ ì¡°íšŒ ìš”ì²­
    KB-->>Context: ê²€ì¦ ê·œì¹™ ë°˜í™˜
    Context->>KB: ì¼ê´€ì„± ê¸°ì¤€ ì¡°íšŒ ìš”ì²­
    KB-->>Context: ì¼ê´€ì„± ê¸°ì¤€ ë°˜í™˜
    Context->>Context: êµ¬ì¡° ë¶„ì„ + ì¼ê´€ì„± ê²€ì¦
    Context-->>Master: ê²€ì¦ ê²°ê³¼
    
    Note over Master: 2ë‹¨ê³„: Prompt Generation
    Master->>Prompt: 6ë‹¨ê³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
    Prompt->>KB: í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìš”ì²­
    KB-->>Prompt: í…œí”Œë¦¿ ë°˜í™˜
    Prompt->>KB: ì½”ë”© íŒ¨í„´ ìš”ì²­
    KB-->>Prompt: íŒ¨í„´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë°˜í™˜
    Prompt->>KB: 5G ë„ë©”ì¸ ì§€ì‹ ìš”ì²­
    KB-->>Prompt: ë„ë©”ì¸ ì§€ì‹ ë°˜í™˜
    Prompt->>Prompt: 0-6ë‹¨ê³„ ìˆœì°¨ ì‹¤í–‰
    Prompt-->>Master: ìƒì„±ëœ í”„ë¡¬í”„íŠ¸
    
    Note over Master: 3ë‹¨ê³„: Quality Assurance
    Master->>Quality: í’ˆì§ˆ ê²€ì¦
    Quality->>KB: ì™„ì„±ë„ ê¸°ì¤€ ìš”ì²­
    KB-->>Quality: ì™„ì„±ë„ ê¸°ì¤€ ë°˜í™˜
    Quality->>KB: ê¸°ìˆ ì  ì •í™•ì„± ê¸°ì¤€ ìš”ì²­
    KB-->>Quality: ê¸°ìˆ ì  ì •í™•ì„± ê¸°ì¤€ ë°˜í™˜
    Quality->>KB: Cursor AI í˜¸í™˜ì„± ê¸°ì¤€ ìš”ì²­
    KB-->>Quality: í˜¸í™˜ì„± ê¸°ì¤€ ë°˜í™˜
    Quality->>Quality: ì™„ì„±ë„ + ì •í™•ì„± + í˜¸í™˜ì„± ê²€ì¦
    Quality-->>Master: í’ˆì§ˆ ì ìˆ˜
    
    Note over Master: 4ë‹¨ê³„: LLM Optimization
    Master->>LLM: GPT-5 ìµœì í™”
    LLM->>LLM: í”„ë¡¬í”„íŠ¸ ìµœì í™”
    LLM-->>Master: ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸
    
    Note over Master: 5ë‹¨ê³„: Output Processing
    Master->>Output: ìµœì¢… ì²˜ë¦¬
    Output->>Output: êµ¬ì¡°í™” + í˜•ì‹ ë³€í™˜
    Output-->>Master: ìµœì¢… ê²°ê³¼
    
    Note over Master: 6ë‹¨ê³„: Feedback Collection
    Master->>Feedback: ì„±ëŠ¥ ë¶„ì„
    Feedback->>KB: ì„±ê³µ ì‚¬ë¡€ ì €ì¥ ìš”ì²­
    KB-->>Feedback: ì €ì¥ ì™„ë£Œ
    Feedback->>Feedback: í’ˆì§ˆ ë¶„ì„ + ê°œì„ ì‚¬í•­ ì‹ë³„
    Feedback-->>Master: í”¼ë“œë°± ë°ì´í„°
    
    Master-->>API: ì²˜ë¦¬ ì™„ë£Œ
    API-->>User: ìµœì í™”ëœ Cursor AI í”„ë¡¬í”„íŠ¸
```

## ğŸ”„ 6-Step Prompt Generation Pipeline

```mermaid
graph TD
    subgraph "ğŸ” Step 0: Project Analysis"
        PA1[ğŸ“ Directory Scanning]
        PA2[ğŸ”— Dependency Mapping] 
        PA3[ğŸ›ï¸ Architecture Identification]
    end
    
    subgraph "ğŸ“„ Step 1: DLD Processing"
        DP1[ğŸ”§ Tech Spec Extraction]
        DP2[ğŸ“Š Requirement Classification]
        DP3[ğŸ“ Markdown Conversion]
        DP4[ğŸ’» Pseudocode Identification]
    end
    
    subgraph "ğŸ§  Step 2: System Context"
        SC1[ğŸ“¡ 5G Domain Knowledge]
        SC2[ğŸ‘¨â€ğŸ’» Coding Guidelines]
        SC3[â­ Quality Standards]
    end
    
    subgraph "ğŸ¤– Step 3: Cursor AI Rules"
        CAR1[ğŸ‘¥ Team Conventions]
        CAR2[ğŸ“ Project Rules]
        CAR3[ğŸ¤– AI Guidelines]
    end
    
    subgraph "ğŸ”„ Step 4: Code Mapping"
        CM1[ğŸ”„ DLD-Code Matching]
        CM2[ğŸ·ï¸ Function Mapping]
        CM3[ğŸ“¦ Module Analysis]
    end
    
    subgraph "ğŸ¨ Step 5: Style Extraction"
        SE1[ğŸ¨ Code Patterns]
        SE2[ğŸ“ Naming Conventions]
        SE3[ğŸ—ï¸ Architecture Style]
        SE4[ğŸ§ª Test Patterns]
    end
    
    subgraph "âš¡ Step 6: Context Enhancement"
        CE1[ğŸ“¡ 5G Protocol Knowledge]
        CE2[âš™ï¸ Hardware Constraints]
        CE3[âš¡ Performance Requirements]
    end
    
    subgraph "ğŸ“š Knowledge Base Calls"
        KB1[ğŸ“š í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿]
        KB2[ğŸ“š ì½”ë”© íŒ¨í„´]
        KB3[ğŸ“š 5G ë„ë©”ì¸ ì§€ì‹]
    end
    
    PA1 --> PA2 --> PA3
    PA3 --> DP1
    DP1 --> DP2 --> DP3 --> DP4
    DP4 --> SC1
    SC1 --> SC2 --> SC3
    SC3 --> CAR1
    CAR1 --> CAR2 --> CAR3
    CAR3 --> CM1
    CM1 --> CM2 --> CM3
    CM3 --> SE1
    SE1 --> SE2 --> SE3 --> SE4
    SE4 --> CE1
    CE1 --> CE2 --> CE3
    
    %% Knowledge Base í˜¸ì¶œ
    SC1 -.->|í˜¸ì¶œ| KB1
    SE1 -.->|í˜¸ì¶œ| KB2
    CE1 -.->|í˜¸ì¶œ| KB3
    
    CE3 --> FINAL[ğŸ“‹ ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±]
    
    %% ìŠ¤íƒ€ì¼ë§
    classDef step fill:#e3f2fd,stroke:#0277bd,stroke-width:2px
    classDef knowledge fill:#fce4ec,stroke:#880e4f,stroke-width:2px
    classDef call stroke:#e91e63,stroke-width:3px,stroke-dasharray: 5 5
    
    class PA1,PA2,PA3,DP1,DP2,DP3,DP4,SC1,SC2,SC3,CAR1,CAR2,CAR3,CM1,CM2,CM3,SE1,SE2,SE3,SE4,CE1,CE2,CE3,FINAL step
    class KB1,KB2,KB3 knowledge
```

## ğŸ“ˆ Quality Assurance Matrix

```mermaid
graph TD
    subgraph "ğŸ›¡ï¸ Quality Dimensions"
        QD1[ğŸ“‹ Completeness<br/>ì™„ì„±ë„ ê²€ì¦]
        QD2[ğŸ”¬ Technical Accuracy<br/>ê¸°ìˆ ì  ì •í™•ì„±]
        QD3[ğŸ¤– Cursor AI Compatibility<br/>í˜¸í™˜ì„± ê²€ì¦]
        QD4[ğŸ’¡ Clarity<br/>ëª…í™•ì„± í‰ê°€]
        QD5[ğŸ¯ Specificity<br/>êµ¬ì²´ì„± ì¸¡ì •]
        QD6[âš¡ Actionability<br/>ì‹¤í–‰ ê°€ëŠ¥ì„±]
    end
    
    subgraph "ğŸ“š Knowledge Base Calls"
        KB1[ğŸ“š ì™„ì„±ë„ ê¸°ì¤€]
        KB2[ğŸ“š ê¸°ìˆ ì  ì •í™•ì„± ê¸°ì¤€]
        KB3[ğŸ“š Cursor AI í˜¸í™˜ì„± ê¸°ì¤€]
        KB4[ğŸ“š ëª…í™•ì„± ê¸°ì¤€]
        KB5[ğŸ“š êµ¬ì²´ì„± ê¸°ì¤€]
        KB6[ğŸ“š ì‹¤í–‰ ê°€ëŠ¥ì„± ê¸°ì¤€]
    end
    
    subgraph "ğŸ“Š Scoring System"
        S1[ê°€ì¤‘ì¹˜ ê³„ì‚°]
        S2[ì„ê³„ê°’ ë¹„êµ]
        S3[ì „ì²´ ì ìˆ˜ ì‚°ì¶œ]
    end
    
    subgraph "ğŸ’¡ Improvement Engine"
        IE1[ë¬¸ì œì  ì‹ë³„]
        IE2[ê°œì„  ì œì•ˆ]
        IE3[ìš°ì„ ìˆœìœ„ ì§€ì •]
    end
    
    %% Knowledge Base í˜¸ì¶œ
    QD1 -.->|í˜¸ì¶œ| KB1
    QD2 -.->|í˜¸ì¶œ| KB2
    QD3 -.->|í˜¸ì¶œ| KB3
    QD4 -.->|í˜¸ì¶œ| KB4
    QD5 -.->|í˜¸ì¶œ| KB5
    QD6 -.->|í˜¸ì¶œ| KB6
    
    QD1 --> S1
    QD2 --> S1
    QD3 --> S1
    QD4 --> S1
    QD5 --> S1
    QD6 --> S1
    
    S1 --> S2 --> S3
    S3 --> IE1 --> IE2 --> IE3
    
    %% ìŠ¤íƒ€ì¼ë§
    classDef quality fill:#e3f2fd,stroke:#0277bd,stroke-width:2px
    classDef knowledge fill:#fce4ec,stroke:#880e4f,stroke-width:2px
    classDef scoring fill:#f1f8e9,stroke:#33691e,stroke-width:2px
    classDef improvement fill:#fff3e0,stroke:#e65100,stroke-width:2px
    classDef call stroke:#e91e63,stroke-width:3px,stroke-dasharray: 5 5
    
    class QD1,QD2,QD3,QD4,QD5,QD6 quality
    class KB1,KB2,KB3,KB4,KB5,KB6 knowledge
    class S1,S2,S3 scoring
    class IE1,IE2,IE3 improvement
```

## ğŸ§© Component Architecture

```mermaid
graph LR
    subgraph "ğŸ¯ Core System"
        direction TB
        MA[Master Agent]
        CVA[Context Validation Agent]
        PGA[Prompt Generator Agent] 
        CQA[Code Quality Agent]
        LLM[LLM Integration]
        POA[Prompt Output Agent]
        FL[Feedback Loop]
    end
    
    subgraph "ğŸ“š Knowledge Layer"
        direction TB
        KM[Knowledge Manager]
        DO[5G Domain Ontology]
        CP[Coding Patterns]
        PT[Prompt Templates]
        SC[Success Cases]
    end
    
    subgraph "ğŸ”§ Infrastructure"
        direction TB
        API[REST API]
        CFG[Configuration]
        LOG[Logging]
        DOC[Docker]
    end
    
    subgraph "ğŸ“Š Data Flow"
        direction LR
        DLD[DLD Input] --> PROMPT[Optimized Prompt]
        METRICS[Quality Metrics] --> FEEDBACK[Improvement Suggestions]
    end
    
    %% Agent to Knowledge Base í˜¸ì¶œ ê´€ê³„
    CVA -.->|í˜¸ì¶œ| KM
    PGA -.->|í˜¸ì¶œ| KM
    CQA -.->|í˜¸ì¶œ| KM
    FL -.->|í˜¸ì¶œ| KM
    
    MA --> CVA
    MA --> PGA
    MA --> CQA
    MA --> LLM
    MA --> POA
    MA --> FL
    
    KM --> DO
    KM --> CP
    KM --> PT
    KM --> SC
    
    API --> MA
    CFG --> MA
    LOG --> MA
```

## âœ¨ Key Features

### ğŸ¤– Multi-Agent Pipeline
- **Context Validation Agent**: DLD verification and preprocessing
- **Prompt Generator Agent**: 6-step prompt generation pipeline
- **Code Quality Agent**: Technical accuracy and compatibility validation
- **LLM Integration**: GPT-5 prompt optimization
- **Prompt Output Agent**: Multi-format output processing
- **Feedback Loop**: Performance monitoring and system improvement

### ğŸ”§ 6-Step Prompt Generation Pipeline
1. **Project Code Structure Analysis**: Directory scanning, dependency mapping, architecture identification
2. **DLD Parsing and Conversion**: Technical spec extraction, requirement classification, markdown conversion
3. **System Prompt Loading**: 5G domain knowledge, coding guidelines, quality standards
4. **Cursor AI Rules Integration**: Team conventions, project rules, AI utilization guidelines
5. **Code Mapping Analysis**: DLD-code matching, function mapping, module structure analysis
6. **Context Enhancement**: 5G protocol knowledge, hardware constraints, performance requirements

### ğŸ“Š Knowledge Base Integration
- **5G Domain Ontology**: Comprehensive 5G technical knowledge
- **Coding Pattern Library**: Reusable implementation patterns
- **Prompt Template Repository**: Proven prompt structures
- **Success Case Database**: Historical performance data

### ğŸ¯ Quality Assurance
- **Technical Accuracy Validation**: 5G domain expertise verification
- **Cursor AI Compatibility**: Optimization for AI code generation
- **Completeness Assessment**: Requirement coverage analysis
- **Performance Benchmarking**: Quality metrics and improvements

## ğŸ“¦ Installation

### Prerequisites
- Python 3.11+
- Docker (optional)
- OpenAI API Key

### Local Development Setup

1. **Clone the repository**:
```bash
git clone <repository-url>
cd dld-cursor-ai-prompt-generator
```

2. **Install dependencies**:
```bash
pip install -r requirements.txt
```

3. **Set up environment variables**:
```bash
cp env.example .env
# Edit .env with your OpenAI API key and other configurations
```

4. **Initialize knowledge base**:
```bash
mkdir -p knowledge_base/data
mkdir -p logs
```

5. **Run the application**:
```bash
python main.py
```

### Docker Deployment

1. **Build and run with Docker Compose**:
```bash
docker-compose up -d
```

2. **Check service health**:
```bash
curl http://localhost:8000/health
```

## ğŸš€ Usage

### REST API

#### Process DLD Document
```bash
curl -X POST "http://localhost:8000/process-dld" \
  -H "Content-Type: application/json" \
  -d '{
    "dld_content": "Your DLD document content here...",
    "project_path": "/path/to/existing/project",
    "output_format": "cursor_ai",
    "quality_threshold": 0.8
  }'
```

#### Upload DLD File
```bash
curl -X POST "http://localhost:8000/upload-dld" \
  -F "file=@your_dld_document.docx" \
  -F "project_path=/path/to/project" \
  -F "output_format=cursor_ai"
```

#### Health Check
```bash
curl http://localhost:8000/health
```

#### Knowledge Base Statistics
```bash
curl http://localhost:8000/knowledge-stats
```

### Example Response

```json
{
  "success": true,
  "prompt": "# 5G gNodeB Implementation...",
  "quality_score": 0.92,
  "validation_results": {
    "completeness_score": 0.89,
    "consistency_score": 0.95,
    "missing_sections": [],
    "technical_accuracy": 0.94
  },
  "execution_time": 45.2,
  "export_formats": {
    "cursor_ai_md": "...",
    "plain_text": "...",
    "structured_json": "..."
  }
}
```

## ğŸ“ Configuration

### Main Configuration (`config.yaml`)

```yaml
# System Settings
debug: false
log_level: "INFO"
max_concurrent_requests: 10

# LLM Configuration
llm:
  provider: "openai"
  model: "gpt-4"
  max_tokens: 4000
  temperature: 0.7

# Quality Thresholds
quality_thresholds:
  dld_completeness: 0.8
  technical_accuracy: 0.9
  prompt_effectiveness: 0.85
```

### Environment Variables

Key environment variables (see `env.example`):

- `OPENAI_API_KEY`: Your OpenAI API key
- `LOG_LEVEL`: Logging level (DEBUG, INFO, WARNING, ERROR)
- `MAX_CONCURRENT_REQUESTS`: Maximum concurrent request limit
- `KNOWLEDGE_BASE_PATH`: Path to knowledge base data

## ğŸ—ï¸ Architecture Details

### Master Agent
The orchestrator that coordinates all sub-agents and manages the processing pipeline.

### Context Validation Agent
- **DLD Structure Analysis**: Parses document structure and identifies sections
- **Missing Information Detection**: Identifies gaps in requirements or specifications
- **Consistency Verification**: Checks for contradictions and inconsistencies

### Prompt Generator Agent
Implements the 6-step pipeline:
1. **Project Analysis**: Scans existing codebase structure
2. **DLD Processing**: Extracts and classifies requirements
3. **System Context**: Loads 5G domain knowledge
4. **Cursor AI Integration**: Applies AI-specific optimizations
5. **Code Mapping**: Maps DLD to existing implementations
6. **Enhancement**: Adds domain-specific context

### Code Quality Agent
- **Completeness Verification**: Ensures all requirements are addressed
- **Technical Accuracy**: Validates 5G domain correctness
- **Cursor AI Compatibility**: Optimizes for AI code generation

### Knowledge Base
- **5G Domain Ontology**: Network functions, interfaces, protocols, technologies
- **Coding Patterns**: Reusable implementation templates
- **Prompt Templates**: Proven prompt structures
- **Success Cases**: Historical performance data

## ğŸ“Š Monitoring and Analytics

### Performance Metrics
- Execution time per component
- Quality scores over time
- Success rates and trends
- System health indicators

### Quality Assessment
- Technical accuracy scores
- Completeness measurements
- Cursor AI compatibility ratings
- User feedback integration

### Feedback Loop
- Continuous performance monitoring
- Automatic improvement identification
- Recommendation generation
- Historical trend analysis

## ğŸ”§ Development

### Project Structure
```
dld-cursor-ai-prompt-generator/
â”œâ”€â”€ agents/                     # Multi-agent system components
â”‚   â”œâ”€â”€ master_agent.py        # Main orchestrator
â”‚   â”œâ”€â”€ context_validation_agent.py
â”‚   â”œâ”€â”€ prompt_generator_agent.py
â”‚   â”œâ”€â”€ code_quality_agent.py
â”‚   â”œâ”€â”€ llm_integration.py
â”‚   â”œâ”€â”€ prompt_output_agent.py
â”‚   â””â”€â”€ feedback_loop.py
â”œâ”€â”€ knowledge_base/            # Knowledge management
â”‚   â”œâ”€â”€ knowledge_manager.py
â”‚   â””â”€â”€ data/                  # Knowledge storage
â”œâ”€â”€ utils/                     # Utilities
â”‚   â”œâ”€â”€ config.py
â”‚   â””â”€â”€ logger.py
â”œâ”€â”€ main.py                    # FastAPI application
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config.yaml
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ Dockerfile
```

### Adding New Agents

1. Create new agent class inheriting from base agent pattern
2. Implement required methods: `initialize()`, `shutdown()`, main processing method
3. Register agent in `MasterAgent`
4. Add configuration in `config.yaml`

### Extending Knowledge Base

1. Add new knowledge categories in `KnowledgeManager`
2. Create data files in `knowledge_base/data/`
3. Implement search and retrieval methods
4. Update domain ontology if needed

## ğŸ§ª Testing

### Unit Tests
```bash
python -m pytest tests/unit/
```

### Integration Tests
```bash
python -m pytest tests/integration/
```

### Performance Tests
```bash
python -m pytest tests/performance/
```

## ğŸ“ˆ Performance Optimization

### Recommendations
1. **Caching**: Implement Redis for knowledge base caching
2. **Parallel Processing**: Use asyncio for concurrent agent execution
3. **Memory Management**: Optimize large document processing
4. **API Optimization**: Implement rate limiting and request queuing

### Scaling
- **Horizontal Scaling**: Deploy multiple instances behind load balancer
- **Database Integration**: Use PostgreSQL for large-scale knowledge storage
- **Message Queues**: Implement async processing with Celery/RQ

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request

### Development Guidelines
- Follow PEP 8 style guide
- Add unit tests for new features
- Update documentation
- Use type hints
- Implement proper error handling

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™‹â€â™‚ï¸ Support

### Documentation
- [API Documentation](docs/api.md)
- [Architecture Guide](docs/architecture.md)
- [Configuration Reference](docs/configuration.md)
- [Deployment Guide](docs/deployment.md)

### Community
- [Issues](../../issues)
- [Discussions](../../discussions)
- [Contributing Guidelines](CONTRIBUTING.md)

## ğŸ”„ Changelog

### Version 1.0.0
- Initial release with complete multi-agent pipeline
- 5G domain knowledge integration
- Cursor AI optimization
- Performance monitoring and feedback loop
- REST API with comprehensive endpoints
- Docker deployment support

## ğŸš§ Roadmap

### Version 1.1.0
- [ ] Advanced NLP processing for DLD analysis
- [ ] Machine learning-based quality prediction
- [ ] Interactive web UI
- [ ] Batch processing capabilities

### Version 1.2.0
- [ ] Multi-language support
- [ ] Custom domain adaptation
- [ ] Advanced analytics dashboard
- [ ] API versioning and backwards compatibility

### Version 2.0.0
- [ ] AI-powered agent optimization
- [ ] Real-time collaboration features
- [ ] Enterprise security features
- [ ] Advanced deployment options
